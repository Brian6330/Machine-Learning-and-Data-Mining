{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9 - Ensemble Learning\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Take the titanic dataset and using all attributes to predict the class ‘Survived’ (convert age and fare into classes ; exclude names from the attribute list) Build a boosting ensemble model with:\n",
    "(a) Adaboost\n",
    "(b) Gradientboost\n",
    "(c) XGB\n",
    "Show the Comparison of the Performance of the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Survived  Pclass  Sex  \\\n",
      "Name                                                                        \n",
      "Mr. Owen Harris Braund                                     0       3    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings         1       1    0   \n",
      "\n",
      "                                                     Age  \\\n",
      "Name                                                       \n",
      "Mr. Owen Harris Braund                              22.0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  38.0   \n",
      "\n",
      "                                                    Siblings/Spouses Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        1   \n",
      "\n",
      "                                                    Parents/Children Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        0   \n",
      "\n",
      "                                                       Fare  AgeGroup  \\\n",
      "Name                                                                    \n",
      "Mr. Owen Harris Braund                               7.2500         2   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  71.2833         2   \n",
      "\n",
      "                                                    FareGroup  \n",
      "Name                                                           \n",
      "Mr. Owen Harris Braund                                      0  \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings          3  \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from IPython.core.display import display\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv(\"data/titanic.csv\", index_col='Name')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "le = preprocessing.LabelEncoder()\n",
    "bins = [0, 4, 18, 65, 100]\n",
    "labels = ['Infant', 'Child', 'Adult', 'Elderly']\n",
    "labels = [1, 2, 3, 4]\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "df[\"AgeGroup\"] = le.fit_transform(df[\"AgeGroup\"])\n",
    "df['FareGroup'] = pd.qcut(x=df['Fare'], q=4)\n",
    "df[\"FareGroup\"] = le.fit_transform(df[\"FareGroup\"])\n",
    "df[\"Survived\"] = le.fit_transform(df[\"Survived\"])\n",
    "df[\"Sex\"] = le.fit_transform(df[\"Sex\"])\n",
    "print(df.head(2))\n",
    "\n",
    "models = {\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'Gradientboost': GradientBoostingClassifier(learning_rate=0.01),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Accuracy  Precision    Recall  F1-Score\nFold                                         \n1     0.820225   0.779412  0.757143  0.768116\n2     0.764045   0.611111  0.758621  0.676923\n3     0.779661   0.716418  0.705882  0.711111\n4     0.762712   0.657143  0.718750  0.686567\n5     0.813559   0.769231  0.735294  0.751880",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.820225</td>\n      <td>0.779412</td>\n      <td>0.757143</td>\n      <td>0.768116</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.764045</td>\n      <td>0.611111</td>\n      <td>0.758621</td>\n      <td>0.676923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.779661</td>\n      <td>0.716418</td>\n      <td>0.705882</td>\n      <td>0.711111</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.762712</td>\n      <td>0.657143</td>\n      <td>0.718750</td>\n      <td>0.686567</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.813559</td>\n      <td>0.769231</td>\n      <td>0.735294</td>\n      <td>0.751880</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradientboost\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Accuracy  Precision    Recall  F1-Score\nFold                                         \n1     0.848315   0.632353  0.955556  0.761062\n2     0.786517   0.541667  0.886364  0.672414\n3     0.819209   0.656716  0.830189  0.733333\n4     0.790960   0.542857  0.883721  0.672566\n5     0.847458   0.646154  0.913043  0.756757",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.848315</td>\n      <td>0.632353</td>\n      <td>0.955556</td>\n      <td>0.761062</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.786517</td>\n      <td>0.541667</td>\n      <td>0.886364</td>\n      <td>0.672414</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.819209</td>\n      <td>0.656716</td>\n      <td>0.830189</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.790960</td>\n      <td>0.542857</td>\n      <td>0.883721</td>\n      <td>0.672566</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.847458</td>\n      <td>0.646154</td>\n      <td>0.913043</td>\n      <td>0.756757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Accuracy  Precision    Recall  F1-Score\nFold                                         \n1     0.837079   0.691176  0.854545  0.764228\n2     0.814607   0.611111  0.897959  0.727273\n3     0.790960   0.776119  0.702703  0.737589\n4     0.768362   0.671429  0.723077  0.696296\n5     0.847458   0.769231  0.806452  0.787402",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.837079</td>\n      <td>0.691176</td>\n      <td>0.854545</td>\n      <td>0.764228</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.814607</td>\n      <td>0.611111</td>\n      <td>0.897959</td>\n      <td>0.727273</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.790960</td>\n      <td>0.776119</td>\n      <td>0.702703</td>\n      <td>0.737589</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.768362</td>\n      <td>0.671429</td>\n      <td>0.723077</td>\n      <td>0.696296</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.847458</td>\n      <td>0.769231</td>\n      <td>0.806452</td>\n      <td>0.787402</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_features = ['Pclass', 'Sex', 'Siblings/Spouses Aboard',\n",
    "                'Parents/Children Aboard', 'AgeGroup', 'FareGroup']\n",
    "\n",
    "\n",
    "def kfold_boost_eval(model, x: pd.DataFrame, y: pd.DataFrame):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=6)\n",
    "    accuracy = np.empty(kf.n_splits)\n",
    "    precision = np.empty(kf.n_splits)\n",
    "    recall = np.empty(kf.n_splits)\n",
    "    f1 = np.empty(kf.n_splits)\n",
    "\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        prediction = model.predict(x_test)\n",
    "\n",
    "        accuracy[i] = accuracy_score(prediction, y_test)\n",
    "        precision[i] = precision_score(prediction, y_test)\n",
    "        recall[i] = recall_score(prediction, y_test)\n",
    "        f1[i] = f1_score(prediction, y_test)\n",
    "        i += 1\n",
    "\n",
    "    print(name)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    a, p, r, f = kfold_boost_eval(model, df[all_features], df[\"Survived\"])\n",
    "    data = {\n",
    "        'Fold': [1, 2, 3, 4, 5],\n",
    "        'Accuracy': a,\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F1-Score': f,\n",
    "    }\n",
    "\n",
    "    scores = pd.DataFrame(data).set_index('Fold')\n",
    "    display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like Gradientboost performs the best out of all 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) With your selected stock / market index using all attributes to predict ‘daily returns’(decision). (‘daily returns’ must first be converted into a decision class that will be used as the target(label), all other attributes must be grouped into classes)\n",
    "(a) Build a voting ensemble model and Explain how the voting technique affects the performance of the model.\n",
    "(b) Stack any models of your choice to create an ensemble.\n",
    "How does stacking compare with voting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000       0\n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996       0\n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002       0\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "2021-09-20  14758.139648  14841.820312  14530.070312  14713.900391   \n",
      "2021-09-21  14803.400391  14847.027344  14696.467773  14779.216797   \n",
      "\n",
      "               Adj Close      Volume  Daily Return  Binary Decision  \\\n",
      "Date                                                                  \n",
      "2021-09-20  14713.900391  4860630000     -0.021940                0   \n",
      "2021-09-21  14779.216797  3083208000      0.004439                1   \n",
      "\n",
      "            Rolling Mean 5  Rolling Mean 10  Rolling Mean 20  Rolling Mean 50  \\\n",
      "Date                                                                            \n",
      "2021-09-20    15027.816016     15126.937012     15143.909961     14875.705195   \n",
      "2021-09-21    14976.107422     15067.425684     15135.738281     14876.624727   \n",
      "\n",
      "            Rolling Mean 200  \n",
      "Date                          \n",
      "2021-09-20      13856.711787  \n",
      "2021-09-21      13868.721973  \n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "stock_df = pd.read_csv(\"data/Nasdaq.csv\", index_col='Date')\n",
    "print(stock_df.head(3))\n",
    "\n",
    "daily_return = np.empty(stock_df['Close'].shape)\n",
    "#  From Slides: Daily return (r): Difference in percentage between\n",
    "#  price at time t+1 and time t\n",
    "daily_return[0] = float('NaN')  # The first\n",
    "daily_return[1:] = np.ediff1d(stock_df['Close']) / stock_df['Close'][:-1]\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Daily Return', value=daily_return)\n",
    "\n",
    "binary = (daily_return > 0).astype(float)\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Binary Decision', value=binary)\n",
    "stock_df[\"Binary Decision\"] = le.fit_transform(stock_df[\"Binary Decision\"])\n",
    "\n",
    "stock_df['Rolling Mean 5'] = stock_df['Close'].rolling(5).mean()\n",
    "stock_df['Rolling Mean 10'] = stock_df['Close'].rolling(10).mean()\n",
    "stock_df['Rolling Mean 20'] = stock_df['Close'].rolling(20).mean()\n",
    "stock_df['Rolling Mean 50'] = stock_df['Close'].rolling(50).mean()\n",
    "stock_df['Rolling Mean 200'] = stock_df['Close'].rolling(200).mean()\n",
    "stock_df = stock_df.fillna(0)  # NAs replaced with zero\n",
    "\n",
    "\n",
    "def estimators() -> list[tuple[str, Any]]:\n",
    "    return [\n",
    "        ('KNN', KNeighborsClassifier(n_neighbors=3)),\n",
    "        ('Tree', DecisionTreeClassifier()),\n",
    "        ('Gaussian Bayes', GaussianNB())\n",
    "    ]\n",
    "\n",
    "\n",
    "# Rest is as you'd expect with fit and predict\n",
    "\n",
    "print(stock_df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Rolling Mean, we already have a sort of grouping, thus I vouch to leave the values ungrouped and just work with the Rolling Mean, especially as it is what was also used in prior exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df[\"Class Daily Return\"] = pd.qcut(stock_df[\"Daily Return\"], q=3)\n",
    "stock_df[\"Class Daily Return\"], _ = stock_df[\"Class Daily Return\"].factorize(sort=True)\n",
    "\n",
    "all_stock_features = ['Volume', 'Rolling Mean 5', 'Rolling Mean 10',\n",
    "                      'Rolling Mean 20', 'Rolling Mean 50', 'Rolling Mean 200']\n",
    "\n",
    "\n",
    "def evaluate(model: Any, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.DataFrame, y_test: pd.DataFrame,\n",
    "             average: Any = 'binary', zero_division: Any = 'warn') -> (float, float, float, float):\n",
    "    \"\"\"\n",
    "    Evaluates a model on a training and test set.\n",
    "    :param model: The model to evaluate\n",
    "    :param average: default='binary': This parameter is required for multiclass/multilabel targets.\n",
    "    :param zero_division: default='warn'\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(pred, y_test)\n",
    "    precision = precision_score(pred, y_test, average=average, zero_division=zero_division)\n",
    "    recall = recall_score(pred, y_test, average=average, zero_division=zero_division)\n",
    "    f1 = f1_score(pred, y_test, average=average, zero_division=zero_division)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def kfold_eval(model: Any, X: pd.DataFrame, y: pd.DataFrame, k: int, average: Any = 'binary',\n",
    "               zero_division: Any = 'warn') -> (np.array, np.array, np.array, np.array):\n",
    "    \"\"\"\n",
    "    Performs k-fold cross-validation on the given model.\n",
    "    :param model: The model to evaluate\n",
    "    :param X: the features to train on\n",
    "    :param y: the labels to predict\n",
    "    :param k: how many folds to perform\n",
    "    :param average: default='binary': This parameter is required for multiclass/multilabel targets.\n",
    "    :param zero_division: default='warn'\n",
    "    :return: accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    accuracy = np.empty(kf.n_splits)\n",
    "    precision = np.empty(kf.n_splits)\n",
    "    recall = np.empty(kf.n_splits)\n",
    "    f1 = np.empty(kf.n_splits)\n",
    "\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        accuracy[i], precision[i], recall[i], f1[i] = evaluate(\n",
    "            model,\n",
    "            X.iloc[train_index],\n",
    "            X.iloc[test_index],\n",
    "            y.iloc[train_index],\n",
    "            y.iloc[test_index],\n",
    "            average,\n",
    "            zero_division,\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def boosting_performance(model: Any, target_feature: str = 'Daily Returns Class', k: int = 5, average: Any = 'binary',\n",
    "                         zero_division: Any = 'warn') -> (np.array, np.array, np.array, np.array):\n",
    "    \"\"\"\n",
    "    Performs a k-fold cross-validation on an SVM with the specified kernel.\n",
    "\n",
    "    :param model: The SVM model\n",
    "    :param target_feature: default='Daily Returns Class': The target feature\n",
    "    :param k: how many folds to perform\n",
    "    :param average: default='binary': This parameter is required for multiclass/multilabel targets.\n",
    "    :param zero_division: default='warn'\n",
    "\n",
    "    :return: accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "    X = stock_df[all_stock_features]\n",
    "    y = stock_df[\"Class Daily Return\"]\n",
    "\n",
    "    return kfold_eval(model=model, X=X, y=y, k=k, average=average, zero_division=zero_division)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting = soft:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Accuracy  Precision    Recall  F1-Score\nFold                                         \n1     0.397420   0.341186  0.334484  0.243252\n2     0.313180   0.336974  0.348685  0.254276\n3     0.333871   0.313802  0.317459  0.307042\n4     0.340726   0.313650  0.308428  0.302055\n5     0.317339   0.327554  0.325754  0.261987",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.397420</td>\n      <td>0.341186</td>\n      <td>0.334484</td>\n      <td>0.243252</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.313180</td>\n      <td>0.336974</td>\n      <td>0.348685</td>\n      <td>0.254276</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.333871</td>\n      <td>0.313802</td>\n      <td>0.317459</td>\n      <td>0.307042</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.340726</td>\n      <td>0.313650</td>\n      <td>0.308428</td>\n      <td>0.302055</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.317339</td>\n      <td>0.327554</td>\n      <td>0.325754</td>\n      <td>0.261987</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting = hard:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Accuracy  Precision    Recall  F1-Score\nFold                                         \n1     0.393793   0.334886  0.349451  0.229639\n2     0.350262   0.330278  0.358524  0.286219\n3     0.310081   0.323959  0.321672  0.305869\n4     0.358468   0.329020  0.329986  0.314219\n5     0.319355   0.333172  0.403910  0.210987",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.393793</td>\n      <td>0.334886</td>\n      <td>0.349451</td>\n      <td>0.229639</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.350262</td>\n      <td>0.330278</td>\n      <td>0.358524</td>\n      <td>0.286219</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.310081</td>\n      <td>0.323959</td>\n      <td>0.321672</td>\n      <td>0.305869</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.358468</td>\n      <td>0.329020</td>\n      <td>0.329986</td>\n      <td>0.314219</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.319355</td>\n      <td>0.333172</td>\n      <td>0.403910</td>\n      <td>0.210987</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "for voting in ['soft', 'hard']:\n",
    "    print(f'Voting = {voting}:')\n",
    "    vote_model = VotingClassifier(estimators=estimators(), voting=voting)\n",
    "\n",
    "    a, p, r, f = boosting_performance(vote_model, k=k_folds, average='macro', zero_division=0)\n",
    "    data = {\n",
    "        'Fold': range(1, k_folds + 1),\n",
    "        'Accuracy': a,\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F1-Score': f,\n",
    "    }\n",
    "\n",
    "    vote_scores = pd.DataFrame(data).set_index('Fold')\n",
    "    display(vote_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hard voting entails picking the prediction with the highest number of votes,\n",
    "whereas soft voting entails combining the probabilities of each prediction in each model and picking the prediction\n",
    "with the highest total probability.\n",
    "\n",
    "Performance is quite similar in this case here though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Stack any models of your choice to create an ensemble. How does stacking compare with voting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Accuracy  Precision    Recall  F1-Score\nFold                                         \n1     0.312374   0.330195  0.317820  0.204012\n2     0.391778   0.337808  0.361225  0.278679\n3     0.293952   0.350124  0.353973  0.245671\n4     0.278226   0.342131  0.353248  0.220650\n5     0.372984   0.364003  0.368794  0.295430",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n    <tr>\n      <th>Fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.312374</td>\n      <td>0.330195</td>\n      <td>0.317820</td>\n      <td>0.204012</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.391778</td>\n      <td>0.337808</td>\n      <td>0.361225</td>\n      <td>0.278679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.293952</td>\n      <td>0.350124</td>\n      <td>0.353973</td>\n      <td>0.245671</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.278226</td>\n      <td>0.342131</td>\n      <td>0.353248</td>\n      <td>0.220650</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.372984</td>\n      <td>0.364003</td>\n      <td>0.368794</td>\n      <td>0.295430</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "k_folds = 5\n",
    "stack_model = StackingClassifier(estimators=estimators(), final_estimator=LogisticRegression(solver='saga', max_iter=5000))\n",
    "\n",
    "a, p, r, f = boosting_performance(stack_model, k=k_folds, average='macro', zero_division=0)\n",
    "data = {\n",
    "    'Fold': range(1, k_folds+1),\n",
    "    'Accuracy': a,\n",
    "    'Precision': p,\n",
    "    'Recall': r,\n",
    "    'F1-Score': f,\n",
    "}\n",
    "\n",
    "stack_scores = pd.DataFrame(data).set_index('Fold')\n",
    "stack_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The stacking classifier is able to learn when our base estimators can be trusted or not.\n",
    " Stacking allows us to use the strength of each individual estimator by using their output as an input of a final estimator.\n",
    "\n",
    "Performance seems to be slightly better with voting than with stacking in our case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}