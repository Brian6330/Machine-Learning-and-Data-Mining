{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Naive Bayes\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Take the titanic dataset and use all attributes to predict the class ‘Survived’ with a k-nearest neighbours classifier, which one do you think is the best distance measure? and why?\n",
    "\n",
    "#### (a) Manhattan distance\n",
    "#### (b) Euclidian distance\n",
    "#### (c) Cosine distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Survived  Pclass  Sex  \\\n",
      "Name                                                                        \n",
      "Mr. Owen Harris Braund                                     0       3    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings         1       1    0   \n",
      "Miss. Laina Heikkinen                                      1       3    0   \n",
      "\n",
      "                                                     Age  \\\n",
      "Name                                                       \n",
      "Mr. Owen Harris Braund                              22.0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  38.0   \n",
      "Miss. Laina Heikkinen                               26.0   \n",
      "\n",
      "                                                    Siblings/Spouses Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        1   \n",
      "Miss. Laina Heikkinen                                                     0   \n",
      "\n",
      "                                                    Parents/Children Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        0   \n",
      "Miss. Laina Heikkinen                                                     0   \n",
      "\n",
      "                                                       Fare AgeGroup  \n",
      "Name                                                                  \n",
      "Mr. Owen Harris Braund                               7.2500        3  \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  71.2833        3  \n",
      "Miss. Laina Heikkinen                                7.9250        3  \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scipy\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"data/titanic.csv\", index_col='Name')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# df.describe(include='all')\n",
    "knnclassifier_man = KNeighborsClassifier(n_neighbors = 5, metric='manhattan')\n",
    "knnclassifier_cos = KNeighborsClassifier(n_neighbors = 5, metric='cosine')\n",
    "knnclassifier_euc = KNeighborsClassifier(n_neighbors = 5, metric='euclidean')\n",
    "le = preprocessing.LabelEncoder()\n",
    "bins = [0, 4, 18, 65, 100]\n",
    "labels = ['Infant', 'Child', 'Adult', 'Elderly']\n",
    "labels = [1, 2, 3, 4]\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "df[\"Survived\"] = le.fit_transform(df[\"Survived\"])\n",
    "df[\"Sex\"] = le.fit_transform(df[\"Sex\"])\n",
    "print(df.head(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN (k = 5) with Manhattan Distance Measure:  0.724\n",
      "Accuracy for KNN (k = 5) with Cosine Distance Measure:  0.724\n",
      "Accuracy for KNN (k = 5) with Euclidean Distance Measure:  0.707\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'Survived'], df[\"Survived\"], test_size=0.4, random_state=6)\n",
    "knnclassifier_man.fit(x_train, y_train)\n",
    "knnclassifier_cos.fit(x_train, y_train)\n",
    "knnclassifier_euc.fit(x_train, y_train)\n",
    "y_pred_man = knnclassifier_man.predict(x_test)\n",
    "y_pred_cos = knnclassifier_cos.predict(x_test)\n",
    "y_pred_euc = knnclassifier_euc.predict(x_test)\n",
    "accuracy_man = accuracy_score(y_test, y_pred_man)\n",
    "accuracy_cos = accuracy_score(y_test, y_pred_cos)\n",
    "accuracy_euc = accuracy_score(y_test, y_pred_euc)\n",
    "print(\"Accuracy for KNN (k = 5) with Manhattan Distance Measure: \", round(accuracy_man, 3))\n",
    "print(\"Accuracy for KNN (k = 5) with Cosine Distance Measure: \", round(accuracy_cos, 3))\n",
    "print(\"Accuracy for KNN (k = 5) with Euclidean Distance Measure: \", round(accuracy_euc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems like both Manhattan and Cosine perform better than the Euclidean distance measure. Generally it depends on your data which measure to use:\n",
    "- Manhattan distance is less intuitive than euclidean and likely to give a higher value than euclidean distance.\n",
    "- Cosine only looks at the direction of vector, but not their magnitude.\n",
    "- Euclidean is not scale in-variant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO\n",
    "#### Build a KNN model with your selected stock / market index using your best distance measure, determine the number attributes that is capable of giving the best prediction. (Select attributes in ascending order(ie 3, 5, 7, ...) and determine the accuracy for the selected attributes, compare the accuracies to find which is the best)\n",
    "\n",
    "First simply import the dataset and set up the values:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "stock_df = pd.read_csv(\"data/Nasdaq.csv\", index_col='Date')\n",
    "print(stock_df.head(3))\n",
    "# stock_df.describe(include='all')\n",
    "\n",
    "stock_knnclassifier_man = KNeighborsClassifier(n_neighbors = 5, metric='manhattan')\n",
    "stock_knnclassifier_cos = KNeighborsClassifier(n_neighbors = 5, metric='cosine')\n",
    "stock_knnclassifier_euc = KNeighborsClassifier(n_neighbors = 5, metric='euclidean')\n",
    "\n",
    "daily_return = np.empty(stock_df['Close'].shape)\n",
    "#  From Slides: Daily return (r): Difference in percentage between the price at time t+1 and at time t\n",
    "daily_return[0] = float('NaN') # The first\n",
    "daily_return[1:] = np.ediff1d(stock_df['Close']) / stock_df['Close'][:-1]\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Daily Return', value=daily_return)\n",
    "\n",
    "binary = (daily_return > 0).astype(float)\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Binary Decision', value=binary)\n",
    "stock_df[\"Binary Decision\"] = le.fit_transform(stock_df[\"Binary Decision\"])\n",
    "\n",
    "stock_df['Rolling Mean 5'] = stock_df['Close'].rolling(5).mean()\n",
    "stock_df['Rolling Mean 10'] = stock_df['Close'].rolling(10).mean()\n",
    "stock_df['Rolling Mean 20'] = stock_df['Close'].rolling(20).mean()\n",
    "stock_df['Rolling Mean 50'] = stock_df['Close'].rolling(50).mean()\n",
    "stock_df['Rolling Mean 200'] = stock_df['Close'].rolling(200).mean()\n",
    "stock_df = stock_df.fillna(0)  # NAs replaced with zero\n",
    "\n",
    "stock_knnclassifier_man.fit(stock_x_train, stock_y_train)\n",
    "stock_knnclassifier_cos.fit(stock_x_train, stock_y_train)\n",
    "stock_knnclassifier_euc.fit(stock_x_train, stock_y_train)\n",
    "stock_y_pred_man = stock_knnclassifier_man.predict(stock_x_test)\n",
    "stock_y_pred_cos = stock_knnclassifier_cos.predict(stock_x_test)\n",
    "stock_y_pred_euc = stock_knnclassifier_euc.predict(stock_x_test)\n",
    "\n",
    "print(stock_df.tail(3))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000       0\n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996       0\n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002       0\n",
      "1971-02-10  100.690002  100.690002  100.690002  100.690002  100.690002       0\n",
      "1971-02-11  101.449997  101.449997  101.449997  101.449997  101.449997       0\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "2021-09-15  15071.339844  15174.379883  14984.679688  15161.530273   \n",
      "2021-09-16  15120.089844  15205.500000  15047.139648  15181.919922   \n",
      "2021-09-17  15163.360352  15166.559570  14998.730469  15043.969727   \n",
      "2021-09-20  14758.139648  14841.820312  14530.070312  14713.900391   \n",
      "2021-09-21  14803.400391  14847.027344  14696.467773  14779.216797   \n",
      "\n",
      "               Adj Close      Volume  Daily Return  Binary Decision  \\\n",
      "Date                                                                  \n",
      "2021-09-15  15161.530273  4446270000      0.008231                1   \n",
      "2021-09-16  15181.919922  3681700000      0.001345                1   \n",
      "2021-09-17  15043.969727  6682650000     -0.009086                0   \n",
      "2021-09-20  14713.900391  4860630000     -0.021940                0   \n",
      "2021-09-21  14779.216797  3083208000      0.004439                1   \n",
      "\n",
      "            Rolling Mean 5  Rolling Mean 10  Rolling Mean 20  Rolling Mean 50  \\\n",
      "Date                                                                            \n",
      "2021-09-15    15133.722070     15233.365918     15086.038477     14855.444590   \n",
      "2021-09-16    15120.456055     15220.619922     15118.838965     14865.781797   \n",
      "2021-09-17    15106.151953     15191.898926     15143.947949     14875.465586   \n",
      "2021-09-20    15027.816016     15126.937012     15143.909961     14875.705195   \n",
      "2021-09-21    14976.107422     15067.425684     15135.738281     14876.624727   \n",
      "\n",
      "            Rolling Mean 200  \n",
      "Date                          \n",
      "2021-09-15      13816.528940  \n",
      "2021-09-16      13831.444839  \n",
      "2021-09-17      13844.889136  \n",
      "2021-09-20      13856.711787  \n",
      "2021-09-21      13868.721973  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting started with the task:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of columns to column Binary Decision\n",
      "Binary Decision     1.000000\n",
      "Daily Return        0.660999\n",
      "Volume              0.022448\n",
      "Close               0.006831\n",
      "Adj Close           0.006831\n",
      "Low                 0.004667\n",
      "Rolling Mean 200    0.003651\n",
      "High                0.003244\n",
      "Rolling Mean 50     0.002230\n",
      "Open                0.001571\n",
      "Rolling Mean 5      0.000909\n",
      "Rolling Mean 20     0.000829\n",
      "Rolling Mean 10     0.000093\n",
      "Name: Binary Decision, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_stock = GaussianNB()\n",
    "print(\"Length of DF: \", stock_df.shape[0])\n",
    "test_size = 100/stock_df.shape[0]\n",
    "print(\"Percentage of test_size to use last 100 days: \", test_size)\n",
    "x_stock_train, x_stock_test, y_stock_train, y_stock_test = train_test_split(\n",
    "    stock_df[[best_stock_attr_fix, second_best_stock_attr_fix]],\n",
    "    stock_df[\"Binary Decision\"], test_size=test_size,\n",
    "    shuffle=False, random_state=6)\n",
    "naive_bayes_stock.fit(x_stock_train, y_stock_train)\n",
    "test_predictions_stock = naive_bayes_stock.predict(x_stock_test)\n",
    "stock_accuracy_man = accuracy_score(stock_y_test, stock_y_pred_man)\n",
    "stock_accuracy_cos = accuracy_score(stock_y_test, stock_y_pred_cos)\n",
    "stock_accuracy_euc = accuracy_score(stock_y_test, stock_y_pred_euc)\n",
    "print(\"Accuracy for KNN (k = 5) with Manhattan Distance Measure: \", round(stock_accuracy_man, 3))\n",
    "print(\"Accuracy for KNN (k = 5) with Cosine Distance Measure: \", round(stock_accuracy_cos, 3))\n",
    "print(\"Accuracy for KNN (k = 5) with Euclidean Distance Measure: \", round(stock_accuracy_euc, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to ignore daily return, open, close; as all of those are directly related to the binary decision\n",
    "(daily return was used to create the binary decision)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of columns to column Binary Decision\n",
      "Binary Decision     1.000000\n",
      "Volume              0.022448\n",
      "Rolling Mean 200    0.003651\n",
      "Rolling Mean 50     0.002230\n",
      "Rolling Mean 5      0.000909\n",
      "Rolling Mean 20     0.000829\n",
      "Rolling Mean 10     0.000093\n",
      "Name: Binary Decision, dtype: float64\n",
      "Volume has the highest correlation, Rolling Mean 200 the second highest\n"
     ]
    }
   ],
   "source": [
    "smaller_stock_df = stock_df[\n",
    "    ['Binary Decision', 'Volume', 'Rolling Mean 5', 'Rolling Mean 10', 'Rolling Mean 20', 'Rolling Mean 50',\n",
    "     'Rolling Mean 200']]\n",
    "\n",
    "correlation_stock_fix = smaller_stock_df.corr()[\"Binary Decision\"]\n",
    "correlation_stock_fix = correlation_stock_fix.apply(lambda entry: abs(entry))\n",
    "\n",
    "print(\"Correlation of columns to column Binary Decision\")\n",
    "temp_correlation_stock_fix = correlation_stock_fix\n",
    "print(temp_correlation_stock_fix.sort_values(ascending=False))\n",
    "temp_correlation_stock_fix.pop(temp_correlation_stock_fix.idxmax())\n",
    "best_stock_attr_fix = temp_correlation_stock_fix.idxmax()\n",
    "temp_correlation_stock_fix.pop(best_stock_attr_fix)\n",
    "second_best_stock_attr_fix = temp_correlation_stock_fix.idxmax()\n",
    "\n",
    "print(best_stock_attr_fix + \" has the highest correlation, \" + second_best_stock_attr_fix + \" the second highest\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
