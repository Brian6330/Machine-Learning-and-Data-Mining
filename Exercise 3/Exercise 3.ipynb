{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Naive Bayes\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Take the titanic dataset and use all attributes to predict the class ‘Survived’ with a k-nearest neighbours classifier, which one do you think is the best distance measure? and why?\n",
    "\n",
    "#### (a) Manhattan distance\n",
    "#### (b) Euclidian distance\n",
    "#### (c) Cosine distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "                                                    Survived  Pclass  Sex  \\\n",
      "Name                                                                        \n",
      "Mr. Owen Harris Braund                                     0       3    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings         1       1    0   \n",
      "Miss. Laina Heikkinen                                      1       3    0   \n",
      "\n",
      "                                                     Age  \\\n",
      "Name                                                       \n",
      "Mr. Owen Harris Braund                              22.0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  38.0   \n",
      "Miss. Laina Heikkinen                               26.0   \n",
      "\n",
      "                                                    Siblings/Spouses Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        1   \n",
      "Miss. Laina Heikkinen                                                     0   \n",
      "\n",
      "                                                    Parents/Children Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        0   \n",
      "Miss. Laina Heikkinen                                                     0   \n",
      "\n",
      "                                                       Fare AgeGroup  \n",
      "Name                                                                  \n",
      "Mr. Owen Harris Braund                               7.2500        3  \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  71.2833        3  \n",
      "Miss. Laina Heikkinen                                7.9250        3  \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scipy\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"data/titanic.csv\", index_col='Name')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# df.describe(include='all')\n",
    "knnclassifier_man = KNeighborsClassifier(n_neighbors = 5, metric='manhattan')\n",
    "knnclassifier_cos = KNeighborsClassifier(n_neighbors = 5, metric='cosine')\n",
    "knnclassifier_euc = KNeighborsClassifier(n_neighbors = 5, metric='euclidean')\n",
    "le = preprocessing.LabelEncoder()\n",
    "bins = [0, 4, 18, 65, 100]\n",
    "labels = ['Infant', 'Child', 'Adult', 'Elderly']\n",
    "labels = [1, 2, 3, 4]\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
    "df[\"Survived\"] = le.fit_transform(df[\"Survived\"])\n",
    "df[\"Sex\"] = le.fit_transform(df[\"Sex\"])\n",
    "print(df.head(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN (k = 5) with Manhattan Distance Measure:  0.724\n",
      "Accuracy for KNN (k = 5) with Cosine Distance Measure:  0.724\n",
      "Accuracy for KNN (k = 5) with Euclidean Distance Measure:  0.707\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'Survived'], df[\"Survived\"], test_size=0.4, random_state=6)\n",
    "knnclassifier_man.fit(x_train, y_train)\n",
    "knnclassifier_cos.fit(x_train, y_train)\n",
    "knnclassifier_euc.fit(x_train, y_train)\n",
    "y_pred_man = knnclassifier_man.predict(x_test)\n",
    "y_pred_cos = knnclassifier_cos.predict(x_test)\n",
    "y_pred_euc = knnclassifier_euc.predict(x_test)\n",
    "accuracy_man = accuracy_score(y_test, y_pred_man)\n",
    "accuracy_cos = accuracy_score(y_test, y_pred_cos)\n",
    "accuracy_euc = accuracy_score(y_test, y_pred_euc)\n",
    "print(\"Accuracy for KNN (k = 5) with Manhattan Distance Measure: \", round(accuracy_man, 3))\n",
    "print(\"Accuracy for KNN (k = 5) with Cosine Distance Measure: \", round(accuracy_cos, 3))\n",
    "print(\"Accuracy for KNN (k = 5) with Euclidean Distance Measure: \", round(accuracy_euc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems like both Manhattan and Cosine perform better than the Euclidean distance measure. Generally it depends on your data which measure to use:\n",
    "- Manhattan distance is less intuitive than euclidean and likely to give a higher value than euclidean distance.\n",
    "- Cosine only looks at the direction of vector, but not their magnitude.\n",
    "- Euclidean is not scale in-variant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Build a KNN model with your selected stock / market index using your best distance measure, determine the number attributes that is capable of giving the best prediction. (Select attributes in ascending order(ie 3, 5, 7, ...) and determine the accuracy for the selected attributes, compare the accuracies to find which is the best)\n",
    "\n",
    "First simply import the dataset and set up the values:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "stock_df = pd.read_csv(\"data/Nasdaq.csv\", index_col='Date')\n",
    "print(stock_df.head(3))\n",
    "# stock_df.describe(include='all')\n",
    "\n",
    "\n",
    "\n",
    "daily_return = np.empty(stock_df['Close'].shape)\n",
    "#  From Slides: Daily return (r): Difference in percentage between the price at time t+1 and at time t\n",
    "daily_return[0] = float('NaN') # The first\n",
    "daily_return[1:] = np.ediff1d(stock_df['Close']) / stock_df['Close'][:-1]\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Daily Return', value=daily_return)\n",
    "\n",
    "binary = (daily_return > 0).astype(float)\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Binary Decision', value=binary)\n",
    "stock_df[\"Binary Decision\"] = le.fit_transform(stock_df[\"Binary Decision\"])\n",
    "\n",
    "stock_df['Rolling Mean 5'] = stock_df['Close'].rolling(5).mean()\n",
    "stock_df['Rolling Mean 10'] = stock_df['Close'].rolling(10).mean()\n",
    "stock_df['Rolling Mean 20'] = stock_df['Close'].rolling(20).mean()\n",
    "stock_df['Rolling Mean 50'] = stock_df['Close'].rolling(50).mean()\n",
    "stock_df['Rolling Mean 200'] = stock_df['Close'].rolling(200).mean()\n",
    "stock_df = stock_df.fillna(0)  # NAs replaced with zero\n",
    "\n",
    "print(stock_df.tail(3))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000       0\n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996       0\n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002       0\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "2021-09-17  15163.360352  15166.559570  14998.730469  15043.969727   \n",
      "2021-09-20  14758.139648  14841.820312  14530.070312  14713.900391   \n",
      "2021-09-21  14803.400391  14847.027344  14696.467773  14779.216797   \n",
      "\n",
      "               Adj Close      Volume  Daily Return  Binary Decision  \\\n",
      "Date                                                                  \n",
      "2021-09-17  15043.969727  6682650000     -0.009086                0   \n",
      "2021-09-20  14713.900391  4860630000     -0.021940                0   \n",
      "2021-09-21  14779.216797  3083208000      0.004439                1   \n",
      "\n",
      "            Rolling Mean 5  Rolling Mean 10  Rolling Mean 20  Rolling Mean 50  \\\n",
      "Date                                                                            \n",
      "2021-09-17    15106.151953     15191.898926     15143.947949     14875.465586   \n",
      "2021-09-20    15027.816016     15126.937012     15143.909961     14875.705195   \n",
      "2021-09-21    14976.107422     15067.425684     15135.738281     14876.624727   \n",
      "\n",
      "            Rolling Mean 200  \n",
      "Date                          \n",
      "2021-09-17      13844.889136  \n",
      "2021-09-20      13856.711787  \n",
      "2021-09-21      13868.721973  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Smaller df and functions we will use. As Cosine and Manhattan had similar results, we will simply use Manhattan.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                      Feature Combination  \\\n53                   [Rolling Mean 5, Rolling Mean 10, Rolling Mean 50, Rolling Mean 200]   \n14                                                     [Rolling Mean 5, Rolling Mean 200]   \n33                                    [Rolling Mean 5, Rolling Mean 10, Rolling Mean 200]   \n51                    [Rolling Mean 5, Rolling Mean 10, Rolling Mean 20, Rolling Mean 50]   \n61  [Rolling Mean 5, Rolling Mean 10, Rolling Mean 20, Rolling Mean 50, Rolling Mean 200]   \n..                                                                                    ...   \n13                                                      [Rolling Mean 5, Rolling Mean 50]   \n31                                     [Rolling Mean 5, Rolling Mean 10, Rolling Mean 20]   \n11                                                      [Rolling Mean 5, Rolling Mean 10]   \n12                                                      [Rolling Mean 5, Rolling Mean 20]   \n2                                                                       [Rolling Mean 10]   \n\n    Accuracy  \n53      0.60  \n14      0.60  \n33      0.59  \n51      0.58  \n61      0.57  \n..       ...  \n13      0.47  \n31      0.45  \n11      0.44  \n12      0.44  \n2       0.44  \n\n[62 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature Combination</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53</th>\n      <td>[Rolling Mean 5, Rolling Mean 10, Rolling Mean 50, Rolling Mean 200]</td>\n      <td>0.60</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[Rolling Mean 5, Rolling Mean 200]</td>\n      <td>0.60</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>[Rolling Mean 5, Rolling Mean 10, Rolling Mean 200]</td>\n      <td>0.59</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>[Rolling Mean 5, Rolling Mean 10, Rolling Mean 20, Rolling Mean 50]</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>[Rolling Mean 5, Rolling Mean 10, Rolling Mean 20, Rolling Mean 50, Rolling Mean 200]</td>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[Rolling Mean 5, Rolling Mean 50]</td>\n      <td>0.47</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>[Rolling Mean 5, Rolling Mean 10, Rolling Mean 20]</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[Rolling Mean 5, Rolling Mean 10]</td>\n      <td>0.44</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[Rolling Mean 5, Rolling Mean 20]</td>\n      <td>0.44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Rolling Mean 10]</td>\n      <td>0.44</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_stock_df = stock_df[\n",
    "    ['Binary Decision', 'Volume', 'Rolling Mean 5', 'Rolling Mean 10',\n",
    "     'Rolling Mean 20', 'Rolling Mean 50', 'Rolling Mean 200']]\n",
    "columns = smaller_stock_df.loc[:, smaller_stock_df.columns != 'Binary Decision'].columns\n",
    "\n",
    "def knn_accuracy(columns):\n",
    "    x = smaller_stock_df[columns]\n",
    "    y = smaller_stock_df['Binary Decision']\n",
    "    test_size = 100/smaller_stock_df.shape[0]\n",
    "\n",
    "    x_stock_train, x_stock_test, y_stock_train, y_stock_test = \\\n",
    "        train_test_split(x, y, test_size=test_size, shuffle=False, random_state=6)\n",
    "\n",
    "    stock_knnclassifier_man = KNeighborsClassifier(metric='manhattan')\n",
    "    stock_knnclassifier_man.fit(x_stock_train, y_stock_train)\n",
    "    stock_y_pred_man = stock_knnclassifier_man.predict(x_stock_test)\n",
    "\n",
    "    return accuracy_score(y_stock_test, stock_y_pred_man)\n",
    "\n",
    "def all_combinations():\n",
    "    for i in range(1, len(columns)):\n",
    "        features_list = [list(c) for c in combinations(columns, i)]\n",
    "        for features in features_list:\n",
    "            yield features\n",
    "\n",
    "accuracies = pd.DataFrame(\n",
    "    map(lambda c: [c, knn_accuracy(c)], all_combinations()),\n",
    "    columns=['Feature Combination', 'Accuracy'],\n",
    ").sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "accuracies\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to ignore daily return, open, close; as all of those are directly related to the binary decision\n",
    "(daily return was used to create the binary decision).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  this works too:\n",
    "#  accuracies = pd.DataFrame(\n",
    "#     map(lambda m: max(map(lambda c: [m, c, knn_accuracy(c)], all_combinations()), key=lambda k: k[2]), ['manhattan']),\n",
    "#     columns=['Metric', 'Feature Combination', 'Accuracy'],\n",
    "# ).sort_values(by='Accuracy', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
