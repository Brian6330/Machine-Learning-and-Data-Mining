{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Simple rules\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1a) What is the best default rule for this dataset? (Default means without any evidence about the person)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without prior knowledge, all we know is whether a person died or not.\n",
    "For this, we can test the two rules \"all dead\" or all \"survived\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "                                                        Survived  Pclass  \\\n",
      "Name                                                                       \n",
      "Mr. Owen Harris Braund                                         0       3   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings             1       1   \n",
      "Miss. Laina Heikkinen                                          1       3   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle                    1       1   \n",
      "Mr. William Henry Allen                                        0       3   \n",
      "Mr. James Moran                                                0       3   \n",
      "Mr. Timothy J McCarthy                                         0       1   \n",
      "Master. Gosta Leonard Palsson                                  0       3   \n",
      "Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson               1       3   \n",
      "Mrs. Nicholas (Adele Achem) Nasser                             1       2   \n",
      "Miss. Marguerite Rut Sandstrom                                 1       3   \n",
      "Miss. Elizabeth Bonnell                                        1       1   \n",
      "Mr. William Henry Saundercock                                  0       3   \n",
      "Mr. Anders Johan Andersson                                     0       3   \n",
      "Miss. Hulda Amanda Adolfina Vestrom                            0       3   \n",
      "Mrs. (Mary D Kingcome) Hewlett                                 1       2   \n",
      "Master. Eugene Rice                                            0       3   \n",
      "Mr. Charles Eugene Williams                                    1       2   \n",
      "Mrs. Julius (Emelia Maria Vandemoortele) Vander Planke         0       3   \n",
      "Mrs. Fatima Masselmani                                         1       3   \n",
      "\n",
      "                                                           Sex   Age  \\\n",
      "Name                                                                   \n",
      "Mr. Owen Harris Braund                                    male  22.0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings      female  38.0   \n",
      "Miss. Laina Heikkinen                                   female  26.0   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle             female  35.0   \n",
      "Mr. William Henry Allen                                   male  35.0   \n",
      "Mr. James Moran                                           male  27.0   \n",
      "Mr. Timothy J McCarthy                                    male  54.0   \n",
      "Master. Gosta Leonard Palsson                             male   2.0   \n",
      "Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson        female  27.0   \n",
      "Mrs. Nicholas (Adele Achem) Nasser                      female  14.0   \n",
      "Miss. Marguerite Rut Sandstrom                          female   4.0   \n",
      "Miss. Elizabeth Bonnell                                 female  58.0   \n",
      "Mr. William Henry Saundercock                             male  20.0   \n",
      "Mr. Anders Johan Andersson                                male  39.0   \n",
      "Miss. Hulda Amanda Adolfina Vestrom                     female  14.0   \n",
      "Mrs. (Mary D Kingcome) Hewlett                          female  55.0   \n",
      "Master. Eugene Rice                                       male   2.0   \n",
      "Mr. Charles Eugene Williams                               male  23.0   \n",
      "Mrs. Julius (Emelia Maria Vandemoortele) Vander Planke  female  31.0   \n",
      "Mrs. Fatima Masselmani                                  female  22.0   \n",
      "\n",
      "                                                        Siblings/Spouses Aboard  \\\n",
      "Name                                                                              \n",
      "Mr. Owen Harris Braund                                                        1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                            1   \n",
      "Miss. Laina Heikkinen                                                         0   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle                                   1   \n",
      "Mr. William Henry Allen                                                       0   \n",
      "Mr. James Moran                                                               0   \n",
      "Mr. Timothy J McCarthy                                                        0   \n",
      "Master. Gosta Leonard Palsson                                                 3   \n",
      "Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson                              0   \n",
      "Mrs. Nicholas (Adele Achem) Nasser                                            1   \n",
      "Miss. Marguerite Rut Sandstrom                                                1   \n",
      "Miss. Elizabeth Bonnell                                                       0   \n",
      "Mr. William Henry Saundercock                                                 0   \n",
      "Mr. Anders Johan Andersson                                                    1   \n",
      "Miss. Hulda Amanda Adolfina Vestrom                                           0   \n",
      "Mrs. (Mary D Kingcome) Hewlett                                                0   \n",
      "Master. Eugene Rice                                                           4   \n",
      "Mr. Charles Eugene Williams                                                   0   \n",
      "Mrs. Julius (Emelia Maria Vandemoortele) Vander Planke                        1   \n",
      "Mrs. Fatima Masselmani                                                        0   \n",
      "\n",
      "                                                        Parents/Children Aboard  \\\n",
      "Name                                                                              \n",
      "Mr. Owen Harris Braund                                                        0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                            0   \n",
      "Miss. Laina Heikkinen                                                         0   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle                                   0   \n",
      "Mr. William Henry Allen                                                       0   \n",
      "Mr. James Moran                                                               0   \n",
      "Mr. Timothy J McCarthy                                                        0   \n",
      "Master. Gosta Leonard Palsson                                                 1   \n",
      "Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson                              2   \n",
      "Mrs. Nicholas (Adele Achem) Nasser                                            0   \n",
      "Miss. Marguerite Rut Sandstrom                                                1   \n",
      "Miss. Elizabeth Bonnell                                                       0   \n",
      "Mr. William Henry Saundercock                                                 0   \n",
      "Mr. Anders Johan Andersson                                                    5   \n",
      "Miss. Hulda Amanda Adolfina Vestrom                                           0   \n",
      "Mrs. (Mary D Kingcome) Hewlett                                                0   \n",
      "Master. Eugene Rice                                                           1   \n",
      "Mr. Charles Eugene Williams                                                   0   \n",
      "Mrs. Julius (Emelia Maria Vandemoortele) Vander Planke                        0   \n",
      "Mrs. Fatima Masselmani                                                        0   \n",
      "\n",
      "                                                           Fare  \n",
      "Name                                                             \n",
      "Mr. Owen Harris Braund                                   7.2500  \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings      71.2833  \n",
      "Miss. Laina Heikkinen                                    7.9250  \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle             53.1000  \n",
      "Mr. William Henry Allen                                  8.0500  \n",
      "Mr. James Moran                                          8.4583  \n",
      "Mr. Timothy J McCarthy                                  51.8625  \n",
      "Master. Gosta Leonard Palsson                           21.0750  \n",
      "Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson        11.1333  \n",
      "Mrs. Nicholas (Adele Achem) Nasser                      30.0708  \n",
      "Miss. Marguerite Rut Sandstrom                          16.7000  \n",
      "Miss. Elizabeth Bonnell                                 26.5500  \n",
      "Mr. William Henry Saundercock                            8.0500  \n",
      "Mr. Anders Johan Andersson                              31.2750  \n",
      "Miss. Hulda Amanda Adolfina Vestrom                      7.8542  \n",
      "Mrs. (Mary D Kingcome) Hewlett                          16.0000  \n",
      "Master. Eugene Rice                                     29.1250  \n",
      "Mr. Charles Eugene Williams                             13.0000  \n",
      "Mrs. Julius (Emelia Maria Vandemoortele) Vander Planke  18.0000  \n",
      "Mrs. Fatima Masselmani                                   7.2250  \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from mlxtend.classifier import OneRClassifier\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "le = preprocessing.LabelEncoder()\n",
    "df = pd.read_csv(\"data/titanic.csv\", index_col='Name')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df.head(20))\n",
    "# df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy if assuming everyone survived : 0.3855693348365276\n",
      "Accuracy if assuming everyone died : 0.6144306651634723\n"
     ]
    }
   ],
   "source": [
    "survived = 0\n",
    "died = 0\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"Survived\"] == 1:\n",
    "        survived += 1\n",
    "    else:\n",
    "        died += 1\n",
    "\n",
    "print(\"Accuracy if assuming everyone survived :\", survived/(survived+died))\n",
    "print(\"Accuracy if assuming everyone died :\", died/(survived+died))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, \"choose most frequent to be the default rule\".\n",
    "In this case, assuming that everyone died is the best default rule, and we should aim to beat with our prediction approaches.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1b) What is the best 1R for this dataset?\n",
    "Very likely, without prior information, we can assume that due to \"mothers and children first\" when the titanic sank,\n",
    "that those are most likely to have survived, thus gender (Sex) or if they are a parent/child.\n",
    "\n",
    "So let's test this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using outdated binary gender:  0.7865168539325843\n",
      "Parents/Children accuracy:  0.5917602996254682\n"
     ]
    }
   ],
   "source": [
    "X_d = df[[\"Sex\"]]\n",
    "y = df[\"Survived\"]\n",
    "Xd_train, Xd_test, y_train, y_test = train_test_split(X_d, y, test_size=0.3, random_state=2)\n",
    "oner = OneRClassifier()\n",
    "oner.fit(Xd_train.to_numpy(), y_train)\n",
    "y_pred = oner.predict(Xd_test.to_numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy using outdated binary gender: \", accuracy)\n",
    "\n",
    "X_d_fam = df[[\"Parents/Children Aboard\"]]\n",
    "y_fam = df[\"Survived\"]\n",
    "Xd_train_fam, Xd_test_fam, y_train_fam, y_test_fam = train_test_split(X_d_fam, y_fam, test_size=0.3, random_state=2)\n",
    "oner_fam = OneRClassifier()\n",
    "oner_fam.fit(Xd_train_fam.to_numpy(), y_train_fam)\n",
    "y_pred_fam = oner_fam.predict(Xd_test_fam.to_numpy())\n",
    "\n",
    "accuracy_fam = accuracy_score(y_test_fam, y_pred_fam)\n",
    "print(\"Parents/Children accuracy: \", accuracy_fam)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus the outdated binary gender within this dataset (M/F) is the best 1R."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1c) Can you produce a second rule based on a single attribute with a good effectiveness?\n",
    "For this we can simply look at all the variants:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_d_fare = df[[\"Fare\"]]\n",
    "y_fare = df[\"Survived\"]\n",
    "Xd_train_fare, Xd_test_fare, y_train_fare, y_test_fare = train_test_split(X_d_fare, y_fare, test_size=0.3, random_state=2)\n",
    "oner_fare = OneRClassifier()\n",
    "oner_fare.fit(Xd_train_fare.to_numpy(), y_train_fare)\n",
    "y_pred_fare = oner_fare.predict(Xd_test_fare.to_numpy())\n",
    "accuracy_fare = accuracy_score(y_test_fare, y_pred_fare)\n",
    "print(\"Fare Accuracy: \", accuracy_fare)\n",
    "\n",
    "X_d_pclass = df[[\"Pclass\"]]\n",
    "y_pclass = df[\"Survived\"]\n",
    "Xd_train_pclass, Xd_test_pclass, y_train_pclass, y_test_pclass = train_test_split(X_d_pclass, y_pclass, test_size=0.3, random_state=2)\n",
    "oner_pclass = OneRClassifier()\n",
    "oner_pclass.fit(Xd_train_pclass.to_numpy(), y_train_pclass)\n",
    "y_pred_pclass = oner_pclass.predict(Xd_test_pclass.to_numpy())\n",
    "\n",
    "accuracy_pclass = accuracy_score(y_test_pclass, y_pred_pclass)\n",
    "print(\"Pclass Accuracy: \", accuracy_pclass)\n",
    "\n",
    "X_d_age = df[[\"Age\"]]\n",
    "y_age = df[\"Survived\"]\n",
    "Xd_train_age, Xd_test_age, y_train_age, y_test_age = train_test_split(X_d_age, y_age, test_size=0.3, random_state=2)\n",
    "oner_age = OneRClassifier()\n",
    "oner_age.fit(Xd_train_age.to_numpy(), y_train_age)\n",
    "y_pred_age = oner_age.predict(Xd_test_age.to_numpy())\n",
    "\n",
    "accuracy_age = accuracy_score(y_test_age, y_pred_age)\n",
    "print(\"Age accuracy: \", accuracy_age)\n",
    "\n",
    "X_d_sib = df[[\"Siblings/Spouses Aboard\"]]\n",
    "y_sib = df[\"Survived\"]\n",
    "Xd_train_sib, Xd_test_sib, y_train_sib, y_test_sib = train_test_split(X_d_sib, y_sib, test_size=0.3, random_state=2)\n",
    "oner_sib = OneRClassifier()\n",
    "oner_sib.fit(Xd_train_sib.to_numpy(), y_train_sib)\n",
    "y_pred_sib = oner_sib.predict(Xd_test_sib.to_numpy())\n",
    "\n",
    "accuracy_sib = accuracy_score(y_test_sib, y_pred_sib)\n",
    "print(\"Sibling/Spouse accuracy: \", accuracy_sib)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, we can conclude that using the Pclass (or Fare which correlates with it) are the best ones.\n",
    "This is likely due to the fact that those who payed more (or are in a better class) are higher up on the ship, farther away from the engines.\n",
    "Thus they had more time to escape.\n",
    "\n",
    "-------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (2) Use a stock / market index for daily return of the day\n",
    "First we simply load the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000       0\n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996       0\n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002       0\n",
      "1971-02-10  100.690002  100.690002  100.690002  100.690002  100.690002       0\n",
      "1971-02-11  101.449997  101.449997  101.449997  101.449997  101.449997       0\n",
      "1971-02-12  102.050003  102.050003  102.050003  102.050003  102.050003       0\n",
      "1971-02-16  102.190002  102.190002  102.190002  102.190002  102.190002       0\n",
      "1971-02-17  101.739998  101.739998  101.739998  101.739998  101.739998       0\n",
      "1971-02-18  101.419998  101.419998  101.419998  101.419998  101.419998       0\n",
      "1971-02-19  100.699997  100.699997  100.699997  100.699997  100.699997       0\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Open          High           Low         Close     Adj Close  \\\ncount  12402.000000  12402.000000  12402.000000  12402.000000  12402.000000   \nmean    2120.657774   2134.377615   2104.791436   2120.585484   2120.585484   \nstd     2692.888884   2709.482136   2673.491669   2693.171132   2693.171132   \nmin       54.869999     54.869999     54.869999     54.869999     54.869999   \n25%      284.700012    284.857498    284.150002    284.477501    284.477501   \n50%     1262.969971   1268.849976   1250.440002   1259.405029   1259.405029   \n75%     2623.209961   2642.297607   2599.407410   2619.670044   2619.670044   \nmax    15375.980469  15403.440430  15343.280273  15374.330078  15374.330078   \n\n             Volume  \ncount  1.240200e+04  \nmean   1.042295e+09  \nstd    1.145532e+09  \nmin    0.000000e+00  \n25%    5.035250e+07  \n50%    5.930600e+08  \n75%    1.870712e+09  \nmax    1.110216e+10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>12402.000000</td>\n      <td>12402.000000</td>\n      <td>12402.000000</td>\n      <td>12402.000000</td>\n      <td>12402.000000</td>\n      <td>1.240200e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2120.657774</td>\n      <td>2134.377615</td>\n      <td>2104.791436</td>\n      <td>2120.585484</td>\n      <td>2120.585484</td>\n      <td>1.042295e+09</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2692.888884</td>\n      <td>2709.482136</td>\n      <td>2673.491669</td>\n      <td>2693.171132</td>\n      <td>2693.171132</td>\n      <td>1.145532e+09</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>54.869999</td>\n      <td>54.869999</td>\n      <td>54.869999</td>\n      <td>54.869999</td>\n      <td>54.869999</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>284.700012</td>\n      <td>284.857498</td>\n      <td>284.150002</td>\n      <td>284.477501</td>\n      <td>284.477501</td>\n      <td>5.035250e+07</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1262.969971</td>\n      <td>1268.849976</td>\n      <td>1250.440002</td>\n      <td>1259.405029</td>\n      <td>1259.405029</td>\n      <td>5.930600e+08</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2623.209961</td>\n      <td>2642.297607</td>\n      <td>2599.407410</td>\n      <td>2619.670044</td>\n      <td>2619.670044</td>\n      <td>1.870712e+09</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15375.980469</td>\n      <td>15403.440430</td>\n      <td>15343.280273</td>\n      <td>15374.330078</td>\n      <td>15374.330078</td>\n      <td>1.110216e+10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "stock_df = pd.read_csv(\"data/Nasdaq.csv\", index_col='Date')\n",
    "print(stock_df.head(10))\n",
    "# stock_df['Date'] = stock_df['Date'].apply(pd.to_datetime)\n",
    "stock_df.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look at daily return histograms:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_return = np.empty(stock_df['Close'].shape)\n",
    "#  From Slides: Daily return (r): Difference in percentage between the price at time t+1 and at time t\n",
    "daily_return[1:] = np.ediff1d(stock_df['Close']) / stock_df['Close'][:-1]\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Daily Return', value=daily_return)\n",
    "\n",
    "bins = int(len(daily_return) / 32)\n",
    "plt.hist(daily_return, bins=bins)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An approach to compare binary and ternary solution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996   \n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002   \n",
      "1971-02-10  100.690002  100.690002  100.690002  100.690002  100.690002   \n",
      "1971-02-11  101.449997  101.449997  101.449997  101.449997  101.449997   \n",
      "1971-02-12  102.050003  102.050003  102.050003  102.050003  102.050003   \n",
      "1971-02-16  102.190002  102.190002  102.190002  102.190002  102.190002   \n",
      "1971-02-17  101.739998  101.739998  101.739998  101.739998  101.739998   \n",
      "1971-02-18  101.419998  101.419998  101.419998  101.419998  101.419998   \n",
      "1971-02-19  100.699997  100.699997  100.699997  100.699997  100.699997   \n",
      "1971-02-22   99.680000   99.680000   99.680000   99.680000   99.680000   \n",
      "1971-02-23   99.720001   99.720001   99.720001   99.720001   99.720001   \n",
      "1971-02-24  100.639999  100.639999  100.639999  100.639999  100.639999   \n",
      "1971-02-25  101.230003  101.230003  101.230003  101.230003  101.230003   \n",
      "1971-02-26  101.339996  101.339996  101.339996  101.339996  101.339996   \n",
      "1971-03-01  101.779999  101.779999  101.779999  101.779999  101.779999   \n",
      "1971-03-02  101.839996  101.839996  101.839996  101.839996  101.839996   \n",
      "1971-03-03  102.070000  102.070000  102.070000  102.070000  102.070000   \n",
      "1971-03-04  102.779999  102.779999  102.779999  102.779999  102.779999   \n",
      "1971-03-05  103.000000  103.000000  103.000000  103.000000  103.000000   \n",
      "\n",
      "            Volume   Daily Return  Binary Decision  Ternary Decision  \n",
      "Date                                                                  \n",
      "1971-02-05       0  1.035870e-311              1.0               1.0  \n",
      "1971-02-08       0   8.399963e-03              1.0               2.0  \n",
      "1971-02-09       0  -7.932785e-04              0.0               1.0  \n",
      "1971-02-10       0  -6.947171e-04              0.0               1.0  \n",
      "1971-02-11       0   7.547865e-03              1.0               2.0  \n",
      "1971-02-12       0   5.914304e-03              1.0               2.0  \n",
      "1971-02-16       0   1.371871e-03              1.0               2.0  \n",
      "1971-02-17       0  -4.403607e-03              0.0               1.0  \n",
      "1971-02-18       0  -3.145269e-03              0.0               1.0  \n",
      "1971-02-19       0  -7.099204e-03              0.0               1.0  \n",
      "1971-02-22       0  -1.012906e-02              0.0               1.0  \n",
      "1971-02-23       0   4.012933e-04              1.0               1.0  \n",
      "1971-02-24       0   9.225814e-03              1.0               2.0  \n",
      "1971-02-25       0   5.862520e-03              1.0               2.0  \n",
      "1971-02-26       0   1.086565e-03              1.0               2.0  \n",
      "1971-03-01       0   4.341844e-03              1.0               2.0  \n",
      "1971-03-02       0   5.894828e-04              1.0               1.0  \n",
      "1971-03-03       0   2.258478e-03              1.0               2.0  \n",
      "1971-03-04       0   6.956002e-03              1.0               2.0  \n",
      "1971-03-05       0   2.140506e-03              1.0               2.0  \n"
     ]
    }
   ],
   "source": [
    "binary = (daily_return > 0).astype(float)\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Binary Decision', value=binary)\n",
    "\n",
    "limit = 0.001\n",
    "ternary = np.zeros(daily_return.shape)\n",
    "ternary[np.where(daily_return > limit)] = 2\n",
    "ternary[np.where(daily_return < limit)] = 1\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Ternary Decision', value=ternary)\n",
    "\n",
    "print(stock_df.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create 1R model using volume:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DF:  887\n",
      "Percentage of test_size to use last 100 days:  0.11273957158962795\n",
      "Binary Accuracy:  0.4267333809864189\n"
     ]
    }
   ],
   "source": [
    "X_d_stock = stock_df[[\"Volume\"]]\n",
    "y_stock = stock_df[\"Binary Decision\"]\n",
    "print(\"Length of DF: \", df.shape[0])\n",
    "test_size = 100/df.shape[0]\n",
    "print(\"Percentage of test_size to use last 100 days: \", test_size)\n",
    "Xd_train_stock, Xd_test_stock, y_train_stock, y_test_stock = train_test_split(X_d_stock, y_stock, test_size=test_size, random_state=2, shuffle=False)\n",
    "oner_stock = OneRClassifier()\n",
    "oner_stock.fit(Xd_train_stock.to_numpy(), y_train_stock)\n",
    "y_pred_stock = oner_stock.predict(Xd_test_stock.to_numpy())\n",
    "accuracy_stock_bi = accuracy_score(y_test_stock, y_pred_stock)\n",
    "print(\"Binary Accuracy: \", accuracy_stock_bi)\n",
    "\n",
    "# As ternary does not play nicely with OneR, using binary only\n",
    "# X_d_stock_ter = stock_df[[\"Volume\"]]\n",
    "# y_stock_ter = stock_df[\"Ternary Decision\"]\n",
    "# Xd_train_stock_ter, Xd_test_stock_ter, y_train_stock_ter, y_test_stock_ter = train_test_split(X_d_stock_ter, y_stock_ter, test_size=0.3)\n",
    "# oner_stock_ter = OneRClassifier()\n",
    "# oner_stock_ter.fit(Xd_train_stock_ter.to_numpy(), y_train_stock_ter)\n",
    "# y_pred_stock_ter = oner_stock_ter.predict(Xd_test_stock_ter.to_numpy())\n",
    "# accuracy_stock_ter = accuracy_score(y_test_stock_ter, y_pred_stock_ter)\n",
    "# print(\"Ternary Accuracy: \", accuracy_stock_ter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}