{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Naive Bayes\n",
    "\n",
    "First name: Brian\n",
    "<br>\n",
    "Last name: Schweigler\n",
    "<br>\n",
    "Matriculation number: 16-102-071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1a) In the correlation visualization, select the two features that have the most significant correlation to the target feature, Survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Survived  Pclass     Sex  \\\n",
      "Name                                                                           \n",
      "Mr. Owen Harris Braund                                     0       3    male   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings         1       1  female   \n",
      "Miss. Laina Heikkinen                                      1       3  female   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle                1       1  female   \n",
      "Mr. William Henry Allen                                    0       3    male   \n",
      "\n",
      "                                                     Age  \\\n",
      "Name                                                       \n",
      "Mr. Owen Harris Braund                              22.0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  38.0   \n",
      "Miss. Laina Heikkinen                               26.0   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle         35.0   \n",
      "Mr. William Henry Allen                             35.0   \n",
      "\n",
      "                                                    Siblings/Spouses Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    1   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        1   \n",
      "Miss. Laina Heikkinen                                                     0   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle                               1   \n",
      "Mr. William Henry Allen                                                   0   \n",
      "\n",
      "                                                    Parents/Children Aboard  \\\n",
      "Name                                                                          \n",
      "Mr. Owen Harris Braund                                                    0   \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings                        0   \n",
      "Miss. Laina Heikkinen                                                     0   \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle                               0   \n",
      "Mr. William Henry Allen                                                   0   \n",
      "\n",
      "                                                       Fare  \n",
      "Name                                                         \n",
      "Mr. Owen Harris Braund                               7.2500  \n",
      "Mrs. John Bradley (Florence Briggs Thayer) Cumings  71.2833  \n",
      "Miss. Laina Heikkinen                                7.9250  \n",
      "Mrs. Jacques Heath (Lily May Peel) Futrelle         53.1000  \n",
      "Mr. William Henry Allen                              8.0500  \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from mlxtend.classifier import OneRClassifier\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"data/titanic.csv\", index_col='Name')\n",
    "# df.describe(include='all')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df.head(5))\n",
    "le = preprocessing.LabelEncoder()\n",
    "#df[\"Name\"] = le.fit_transform(df[\"Name\"])\n",
    "df[\"Survived\"] = le.fit_transform(df[\"Survived\"])\n",
    "df[\"Sex\"] = le.fit_transform(df[\"Sex\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of columns to column survived\n",
      "Survived                   1.000000\n",
      "Sex                        0.542152\n",
      "Pclass                     0.336528\n",
      "Fare                       0.256179\n",
      "Parents/Children Aboard    0.080097\n",
      "Age                        0.059665\n",
      "Siblings/Spouses Aboard    0.037082\n",
      "Name: Survived, dtype: float64\n",
      "Sex has the highest correlation, Pclass the second highest\n"
     ]
    }
   ],
   "source": [
    "correlation = df.corr()[\"Survived\"]\n",
    "correlation = correlation.apply(lambda entry: abs(entry))\n",
    "\n",
    "print(\"Correlation of columns to column survived\")\n",
    "print(correlation.sort_values(ascending=False))\n",
    "\n",
    "correlation.pop(correlation.idxmax())\n",
    "temp_correlation = correlation\n",
    "best = correlation.idxmax()\n",
    "temp_correlation.pop(best)\n",
    "second_best = temp_correlation.idxmax()\n",
    "\n",
    "print(best + \" has the highest correlation, \" + second_best + \" the second highest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1b) Using Naive Bayes classifier and the most two significant features to predict the Survival of the travellers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is for Naive Bayes  0.803\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[[best, second_best]], df[\"Survived\"], test_size=0.4,\n",
    "                                                    random_state=6)\n",
    "naive_bayes.fit(x_train, y_train)\n",
    "test_predictions = naive_bayes.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy is for Naive Bayes \", round(accuracy, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1c) Compare the performance of your model when using all the attributes of the travellers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using all attributes for Naive Bayes  0.752\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_all = GaussianNB()\n",
    "x_train_all, x_test_all, y_train_all, y_test_all = train_test_split(df.loc[:, df.columns != 'Survived'], df[\"Survived\"],\n",
    "                                                                    test_size=0.4, random_state=6)\n",
    "naive_bayes_all.fit(x_train_all, y_train_all)\n",
    "test_predictions_all = naive_bayes_all.predict(x_test_all)\n",
    "accuracy_all = accuracy_score(y_test_all, test_predictions_all)\n",
    "print(\"Accuracy using all attributes for Naive Bayes \", round(accuracy_all, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus using all columns is not only less efficient, but also performs worse.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (2a) Select the two features that have the most signifcant correlation to the target feature, daily return.\n",
    "\n",
    "First simply import the dataset and set up the values:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "stock_df = pd.read_csv(\"data/Nasdaq.csv\", index_col='Date')\n",
    "print(stock_df.head(5))\n",
    "# stock_df['Date'] = stock_df['Date'].apply(pd.to_datetime)\n",
    "stock_df.describe(include='all')\n",
    "\n",
    "\n",
    "daily_return = np.empty(stock_df['Close'].shape)\n",
    "#  From Slides: Daily return (r): Difference in percentage between the price at time t+1 and at time t\n",
    "daily_return[0] = float('NaN') # The first\n",
    "daily_return[1:] = np.ediff1d(stock_df['Close']) / stock_df['Close'][:-1]\n",
    "stock_df.insert(loc=len(stock_df.columns), column='Daily Return', value=daily_return)\n",
    "\n",
    "# for i in range(1, len(stock_df)):\n",
    "#     p_t = stock_df.loc[i, 'Close']\n",
    "#     p_t_minus_1 = stock_df.loc[i - 1, 'Close']\n",
    "#     daily_return = (p_t - p_t_minus_1) / p_t_minus_1\n",
    "#     stock_df.loc[i, 'Daily Return'] = daily_return\n",
    "\n",
    "stock_df['Rolling Mean 5'] = stock_df['Close'].rolling(5).mean()\n",
    "stock_df['Rolling Mean 10'] = stock_df['Close'].rolling(10).mean()\n",
    "stock_df['Rolling Mean 20'] = stock_df['Close'].rolling(20).mean()\n",
    "stock_df['Rolling Mean 50'] = stock_df['Close'].rolling(50).mean()\n",
    "stock_df['Rolling Mean 200'] = stock_df['Close'].rolling(200).mean()\n",
    "stock_df = stock_df.fillna(0)  # NAs replaced with zero\n",
    "\n",
    "print(stock_df.tail(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000  100.000000       0\n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996  100.839996       0\n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002  100.760002       0\n",
      "1971-02-10  100.690002  100.690002  100.690002  100.690002  100.690002       0\n",
      "1971-02-11  101.449997  101.449997  101.449997  101.449997  101.449997       0\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "2021-09-15  15071.339844  15174.379883  14984.679688  15161.530273   \n",
      "2021-09-16  15120.089844  15205.500000  15047.139648  15181.919922   \n",
      "2021-09-17  15163.360352  15166.559570  14998.730469  15043.969727   \n",
      "2021-09-20  14758.139648  14841.820312  14530.070312  14713.900391   \n",
      "2021-09-21  14803.400391  14847.027344  14696.467773  14779.216797   \n",
      "\n",
      "               Adj Close      Volume  Daily Return  Rolling Mean 5  \\\n",
      "Date                                                                 \n",
      "2021-09-15  15161.530273  4446270000      0.008231    15133.722070   \n",
      "2021-09-16  15181.919922  3681700000      0.001345    15120.456055   \n",
      "2021-09-17  15043.969727  6682650000     -0.009086    15106.151953   \n",
      "2021-09-20  14713.900391  4860630000     -0.021940    15027.816016   \n",
      "2021-09-21  14779.216797  3083208000      0.004439    14976.107422   \n",
      "\n",
      "            Rolling Mean 10  Rolling Mean 20  Rolling Mean 50  \\\n",
      "Date                                                            \n",
      "2021-09-15     15233.365918     15086.038477     14855.444590   \n",
      "2021-09-16     15220.619922     15118.838965     14865.781797   \n",
      "2021-09-17     15191.898926     15143.947949     14875.465586   \n",
      "2021-09-20     15126.937012     15143.909961     14875.705195   \n",
      "2021-09-21     15067.425684     15135.738281     14876.624727   \n",
      "\n",
      "            Rolling Mean 200  \n",
      "Date                          \n",
      "2021-09-15      13816.528940  \n",
      "2021-09-16      13831.444839  \n",
      "2021-09-17      13844.889136  \n",
      "2021-09-20      13856.711787  \n",
      "2021-09-21      13868.721973  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting started with the task:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}